{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812fb05b-1c20-42e2-b55a-1a3f17d4f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c53164-2268-4520-b41f-1e1eb63c3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "005887be-c122-4e76-b4fc-9dea1faed9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp_ID        Name Department                   Email   Join_Date\n",
      "0     E1    Asha Rao         IT      asha.rao@gmail.com  2021-06-15\n",
      "1     E2  Ravi Kumar         HR  ravi_kumar@company.com  2020-01-10\n",
      "2     E3  Neha Singh         IT      neha.s@company.com  2022-03-25\n",
      "3     E4   Arjun Das    Finance     arjun.das@gmail.com  2019-11-05\n"
     ]
    }
   ],
   "source": [
    "employees = pd.DataFrame({\n",
    "    'Emp_ID': ['E1', 'E2', 'E3', 'E4'],\n",
    "    'Name': ['Asha Rao', 'Ravi Kumar', 'Neha Singh', 'Arjun Das'],\n",
    "    'Department': ['IT', 'HR', 'IT', 'Finance'],\n",
    "    'Email': ['asha.rao@gmail.com', 'ravi_kumar@company.com', 'neha.s@company.com', 'arjun.das@gmail.com'],\n",
    "    'Join_Date': ['2021-06-15', '2020-01-10', '2022-03-25', '2019-11-05']\n",
    "})\n",
    "salaries = pd.DataFrame({\n",
    "    'Emp_ID': ['E1', 'E2', 'E3', 'E4'],\n",
    "    'Salary': [60000, 50000, 75000, 65000]\n",
    "})\n",
    "df=pd.DataFrame(employees)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934c3909-c17d-449d-9670-27305c7d20fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp_ID        Name Department                   Email   Join_Date  Salary\n",
      "0     E1    Asha Rao         IT      asha.rao@gmail.com  2021-06-15   60000\n",
      "1     E2  Ravi Kumar         HR  ravi_kumar@company.com  2020-01-10   50000\n",
      "2     E3  Neha Singh         IT      neha.s@company.com  2022-03-25   75000\n",
      "3     E4   Arjun Das    Finance     arjun.das@gmail.com  2019-11-05   65000\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(employees, salaries, on='Emp_ID')\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "947d0d07-bedc-4ff6-b6c2-7917d8ab2fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp_ID        Name Department                   Email   Join_Date  Salary\n",
      "0     E1    Asha Rao         IT      asha.rao@gmail.com  2021-06-15   60000\n",
      "1     E2  Ravi Kumar         HR  ravi_kumar@company.com  2020-01-10   50000\n",
      "2     E3  Neha Singh         IT      neha.s@company.com  2022-03-25   75000\n",
      "3     E4   Arjun Das    Finance     arjun.das@gmail.com  2019-11-05   65000\n"
     ]
    }
   ],
   "source": [
    "#2Ô∏è‚É£ Left Merge\n",
    "#Input\n",
    " #All rows from employees\n",
    "#Expected Output\n",
    " #All employees retained even if salary is missing\n",
    "#Task\n",
    " #Merge such that every employee appears in the result.\n",
    "\n",
    "left_merged_df = pd.merge(employees,salaries,on=\"Emp_ID\",how=\"left\")\n",
    "print(left_merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532cc89a-a3d7-4d49-b2fe-fea5407d41a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp_ID        Name Department                   Email   Join_Date  Salary\n",
      "0     E1    Asha Rao         IT      asha.rao@gmail.com  2021-06-15   60000\n",
      "1     E2  Ravi Kumar         HR  ravi_kumar@company.com  2020-01-10   50000\n",
      "2     E3  Neha Singh         IT      neha.s@company.com  2022-03-25   75000\n",
      "3     E4   Arjun Das    Finance     arjun.das@gmail.com  2019-11-05   65000\n"
     ]
    }
   ],
   "source": [
    "#3Ô∏è‚É£ Right Merge\n",
    "#Input\n",
    " #All rows from salaries\n",
    "#Expected Output\n",
    " #Only employees present in salary table appear\n",
    "##Merge ensuring all salary records are preserved.\n",
    "import pandas as pd\n",
    "\n",
    "right_merged_df = pd.merge(employees,salaries,on=\"Emp_ID\",how=\"right\")\n",
    "\n",
    "print(right_merged_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64be5a6d-3d89-40d8-a6da-4b4bd308cd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Emp_ID        Name Department                   Email   Join_Date  Salary\n",
      "0     E1    Asha Rao         IT      asha.rao@gmail.com  2021-06-15   60000\n",
      "1     E2  Ravi Kumar         HR  ravi_kumar@company.com  2020-01-10   50000\n",
      "2     E3  Neha Singh         IT      neha.s@company.com  2022-03-25   75000\n",
      "3     E4   Arjun Das    Finance     arjun.das@gmail.com  2019-11-05   65000\n"
     ]
    }
   ],
   "source": [
    "#4Ô∏è‚É£ Inner Merge Condition Check\n",
    "#Input\n",
    " #Merge on Emp_ID\n",
    "#Expected Output\n",
    " #Only matching Emp_ID rows\n",
    "#Task\n",
    " #Create a merged table that keeps only common records.\n",
    "import pandas as pd\n",
    "\n",
    "inner_merged_df = pd.merge(employees,salaries,on=\"Emp_ID\",how=\"inner\")\n",
    "\n",
    "print(inner_merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4339443-b9e5-43c7-9e2b-55b02f323936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name Department  Salary\n",
      "0    Asha Rao         IT   60000\n",
      "1  Ravi Kumar         HR   50000\n",
      "2  Neha Singh         IT   75000\n",
      "3   Arjun Das    Finance   65000\n"
     ]
    }
   ],
   "source": [
    "#5Ô∏è‚É£ Selecting Columns After Merge\n",
    "#Input\n",
    " #Merged DataFrame\n",
    "#Expected Output\n",
    "#Name\n",
    "#Department\n",
    "#Salary\n",
    "#Task\n",
    " #Extract only Name, Department, and Salary from the merged result.\n",
    "# Assuming merged_df already exists\n",
    "selected_df = merged_df[[\"Name\", \"Department\", \"Salary\"]]\n",
    "\n",
    "print(selected_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77facde7-0222-4f35-b3d6-9aaf23051216",
   "metadata": {},
   "source": [
    "## üîπ PART 2: STRING METHODS (.str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37503aa7-994f-42b7-b30d-5dca7c39bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ASHA RAO\n",
      "1    RAVI KUMAR\n",
      "2    NEHA SINGH\n",
      "3     ARJUN DAS\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#6Ô∏è‚É£ Convert Names to Uppercase\n",
    "##Name column\n",
    "#Expected Output\n",
    "#ASHA RAO, RAVI KUMAR, NEHA SINGH, ARJUN DAS\n",
    "#Task\n",
    " #Convert all employee names to uppercase.\n",
    "# Convert Name column to uppercase\n",
    "merged_df[\"Name\"] = merged_df[\"Name\"].str.upper()\n",
    "\n",
    "print(merged_df[\"Name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30253e71-78a8-4221-82bd-8a79c70ecf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      gmail.com\n",
      "1    company.com\n",
      "2    company.com\n",
      "3      gmail.com\n",
      "Name: Email_Domain, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#7Ô∏è‚É£ Extract Email Domain\n",
    "#Input\n",
    " #Email column\n",
    "#Expected Output\n",
    "#gmail.com, company.com, company.com, gmail.com\n",
    "#Task\n",
    " #Extract only the domain part from each email.\n",
    "# Extract domain from Email column\n",
    "merged_df[\"Email_Domain\"] = merged_df[\"Email\"].str.split(\"@\").str[1]\n",
    "\n",
    "print(merged_df[\"Email_Domain\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f06754f1-b50d-455f-88d2-e5427718b626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "Name: Is_Company_Email, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#8Ô∏è‚É£ Check Company Email\n",
    "#Input\n",
    " #Email column\n",
    "#Expected Output\n",
    "#False, True, True, False\n",
    "#Task\n",
    " #Identify which emails belong to the company domain.\n",
    "# Create boolean column for company email\n",
    "merged_df[\"Is_Company_Email\"] = merged_df[\"Email\"].str.endswith(\"company.com\")\n",
    "\n",
    "print(merged_df[\"Is_Company_Email\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d400ca9-d68b-4dec-bcf6-a6983dd2a86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ASHA_RAO\n",
      "1    RAVI_KUMAR\n",
      "2    NEHA_SINGH\n",
      "3     ARJUN_DAS\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#9Ô∏è‚É£ Replace Spaces in Names\n",
    "#Input\n",
    " #Name column\n",
    "#Expected Output\n",
    "#Asha_Rao, Ravi_Kumar, Neha_Singh, Arjun_Das\n",
    "#Task\n",
    " #Replace spaces with underscores.\n",
    "# Replace spaces with underscores\n",
    "merged_df[\"Name\"] = merged_df[\"Name\"].str.replace(\" \", \"_\", regex=False)\n",
    "\n",
    "print(merged_df[\"Name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f7595fc-db2e-4057-ba07-c51129592e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     8\n",
      "1    10\n",
      "2    10\n",
      "3     9\n",
      "Name: Name_Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#üîü Name Length Calculation\n",
    "#Input\n",
    " #Name column\n",
    "#Expected Output\n",
    "#8, 10, 10, 9\n",
    "#Task\n",
    "# Find the length of each employee name.\n",
    "# Calculate length of each name\n",
    "merged_df[\"Name_Length\"] = merged_df[\"Name\"].str.len()\n",
    "\n",
    "print(merged_df[\"Name_Length\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e2ff6-c1fa-49fc-b1bf-194a9f7fd3d5",
   "metadata": {},
   "source": [
    "## üîπ PART 3: DATETIME CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "375bb96b-f5d6-4067-97d4-79f760d2acaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#1Ô∏è‚É£1Ô∏è‚É£ Convert Join_Date to Datetime\n",
    "#Input\n",
    "# Join_Date column (string format)\n",
    "#Expected Output\n",
    "#datetime64[ns]\n",
    "#Task\n",
    " #Convert the Join_Date column into datetime format.\n",
    "# Convert Join_Date to datetime\n",
    "merged_df[\"Join_Date\"] = pd.to_datetime(merged_df[\"Join_Date\"])\n",
    "\n",
    "print(merged_df[\"Join_Date\"].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38d771e8-7862-4d82-933b-10cfd6978521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2021\n",
      "1    2020\n",
      "2    2022\n",
      "3    2019\n",
      "Name: Join_Year, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#1Ô∏è‚É£2Ô∏è‚É£ Extract Year\n",
    "#Input\n",
    " #Join_Date column\n",
    "#Expected Output\n",
    "#2021, 2020, 2022, 2019\n",
    "#Task\n",
    " #Extract the year each employee joined.\n",
    "merged_df[\"Join_Date\"] = pd.to_datetime(merged_df[\"Join_Date\"])\n",
    "merged_df[\"Join_Year\"] = merged_df[\"Join_Date\"].dt.year\n",
    "print(merged_df[\"Join_Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89186d7e-9817-40f7-9d6d-84471d956fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     6\n",
      "1     1\n",
      "2     3\n",
      "3    11\n",
      "Name: Join_Month, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#1Ô∏è‚É£3Ô∏è‚É£ Extract Month\n",
    "#Input\n",
    " #Join_Date column\n",
    "##Expected Output\n",
    "#6, 1, 3, 11Task\n",
    " #Extract the month from Join_Date.\n",
    "merged_df[\"Join_Date\"] = pd.to_datetime(merged_df[\"Join_Date\"])\n",
    "merged_df[\"Join_Month\"] = merged_df[\"Join_Date\"].dt.month\n",
    "print(merged_df[\"Join_Month\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70ba0469-345d-4824-ba8c-d7334b1aeb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    15\n",
      "1    10\n",
      "2    25\n",
      "3     5\n",
      "Name: Join_Day, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#1Ô∏è‚É£4Ô∏è‚É£ Extract Day\n",
    "##Join_Date column\n",
    "#Expected Output\n",
    "#15, 10, 25, 5\n",
    "#Task\n",
    " #Extract the day of joining.\n",
    "\n",
    "merged_df[\"Join_Date\"] = pd.to_datetime(merged_df[\"Join_Date\"])\n",
    "merged_df[\"Join_Day\"] = merged_df[\"Join_Date\"].dt.day\n",
    "print(merged_df[\"Join_Day\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79dee7bc-9196-46b6-aeab-ca73bb577caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Tuesday\n",
      "1     Friday\n",
      "2     Friday\n",
      "3    Tuesday\n",
      "Name: Join_Day_Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#1Ô∏è‚É£5Ô∏è‚É£ Extract Day Name\n",
    "#Input\n",
    " #Join_Date column\n",
    "#Expected Output\n",
    "#Tuesday, Friday, Friday, Tuesday\n",
    "#Task\n",
    " #Find the weekday name for each joining date.\n",
    "merged_df[\"Join_Date\"] = pd.to_datetime(merged_df[\"Join_Date\"])\n",
    "merged_df[\"Join_Day_Name\"] = merged_df[\"Join_Date\"].dt.day_name()\n",
    "print(merged_df[\"Join_Day_Name\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06438a0d-5c07-4b17-915b-3aea5ef6087f",
   "metadata": {},
   "source": [
    "## üîπ PART 4: DATE-BASED FILTERING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb038c23-dd51-414e-97c4-aa82447cd8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name  Join_Date\n",
      "0    ASHA_RAO 2021-06-15\n",
      "2  NEHA_SINGH 2022-03-25\n"
     ]
    }
   ],
   "source": [
    "#1Ô∏è‚É£6Ô∏è‚É£ Employees Joined After 2020\n",
    "#Input\n",
    " #Join_Date > 2020\n",
    "#Expected Output\n",
    "#Name\n",
    "#Join_Dae\n",
    "#Task\n",
    " #Filter employees who joined after the year 2020.\n",
    "merged_df[\"Join_Date\"] = pd.to_datetime(merged_df[\"Join_Date\"])\n",
    "filtered_df = merged_df[merged_df[\"Join_Date\"] > \"2020-12-31\"]\n",
    "result = filtered_df[[\"Name\", \"Join_Date\"]]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e13a6c13-7a84-416d-8332-ad7a7efab3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name Department  Join_Date\n",
      "2  NEHA_SINGH         IT 2022-03-25\n"
     ]
    }
   ],
   "source": [
    "#1Ô∏è‚É£7Ô∏è‚É£ Employees Joined in IT After 2021\n",
    "##Department = IT\n",
    " #Join year > 2021\n",
    "#Expected Output\n",
    "#Name\n",
    "#Department\n",
    "#Join_Date\n",
    "#Task\n",
    " #Apply multiple conditions using department and joining year.\n",
    "merged_df[\"Join_Date\"] = pd.to_datetime(merged_df[\"Join_Date\"])\n",
    "filtered_df = merged_df[\n",
    "    (merged_df[\"Department\"] == \"IT\") &\n",
    "    (merged_df[\"Join_Date\"].dt.year > 2021)\n",
    "]\n",
    "result = filtered_df[[\"Name\", \"Department\", \"Join_Date\"]]\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7094e6fa-549e-4a77-a7e4-b0adec324dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name  Join_Year\n",
      "0    ASHA_RAO       2021\n",
      "1  RAVI_KUMAR       2020\n",
      "2  NEHA_SINGH       2022\n",
      "3   ARJUN_DAS       2019\n"
     ]
    }
   ],
   "source": [
    "#1Ô∏è‚É£8Ô∏è‚É£ Add Join Year Column\n",
    "#Input\n",
    " #Join_Date column\n",
    "#Expected Output\n",
    "#Name\n",
    "#Join_Year\n",
    "#Task\n",
    " #Create a new column containing the joining year.\n",
    "merged_df[\"Join_Date\"] = pd.to_datetime(merged_df[\"Join_Date\"])\n",
    "merged_df[\"Join_Year\"] = merged_df[\"Join_Date\"].dt.year\n",
    "result = merged_df[[\"Name\", \"Join_Year\"]]\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4631643b-cf05-43ee-9311-fc7909e90e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
